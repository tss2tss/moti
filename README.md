Superior automatic screening for human helminthic ova by using self-supervised learning approach-based object classification
Natchapon Pinetsuksai1, Veerayuth Kittichai2, Rangsan Jomtarak3, Komgrit Jaksukam1, Teerawat Tongloy1, Siridech Boonsang4, Santhad Chuwongin1*
1College of Advanced Manufacturing Innovation, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand
{63609007, komgrit.ja, santhad.ch}@kmitl.ac.th, teerawat_tongloy@kkumail.com
2Faculty of Medicine, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand
veerayuth.ki@kmitl.ac.th
3Faculty of Science and Technology, Suan Dusit University, Bangkok, Thailand
Rangsan_jom@dusit.ac.th
4Department of Electrical Engineering, School of Engineering, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand
siridech.bo@kmitl.ac.th
Abstract. Human parasitic infections remain a pressing public health concern for 1.5 billion people worldwide, including those in Thailand. Conventional microscopic examination, a gold standard method, is typically used to identify helminth ova, filariform larvae, and protozoa cysts in stool-dependent simple smears. However, the benefits of these traditional techniques are offset by time-consuming procedures, substantial labor, and the need for skilled and trained parasitologists. An automated rapid screening for those most in need of treatment is considered a potential replacement for these conventional techniques. This study aimed to develop a deep convolutional residual network-based self-supervised learning model to identify the most common parasitic ova in Thailand. Despite utilizing small amounts of training data, the proposed model demonstrated superior performance with over 95% accuracy. It exhibited robustness, as indicated by low values of false positives and negatives in the confusion matrix. Moreover, the model achieved general accuracy exceeding 94% under the ROC curve in self-supervised learning. Interestingly, using only 1% to 10% of fine-tuned, labeled data resulted in a model comparable to one trained with 100% labeled data. These promising results underscore the potential of the Bootstrap Your Own Latent (BYOL) method and our model as invaluable tools for future parasitic infection screening, particularly in resource-limited settings.
Keywords: Helminthic eggs, Bootstrap Your Own Latent (BYOL), Similarity loss, Self-supervised learning, Object classification.
Introduction
Human parasitic infections remain one of public health concerns for 1.5 billion people worldwide including Thailand. The parasite can cause asymptomatic to severe conditions in gastrointestinal tract diseases (including abdominal pain, diarrhea, loss of appetite and malnutrition), and also affecting school-aged absent and developmental impairment in children. Specifically, more than 24% of global population affected soil-transmitted helminth (STH) infection, who’s commonly reported in Thailand such helminths (Ascaris lumbricoides, Hookworm, Strongyloides stercoralis, Taenia species and Opisthorchis viverrini) and pathogenic protozoa (Entamoeba histolytica, Giardia intestinalis and Blastocystis hominis) [1]. Several transmission modes of the parasite to human beings were reported which mainly include digestion of contaminated and uncooked food and drinking water and also skin contact with filariform larval stage. Life threatening by the pathogenic parasite infection can happen if not accurate diagnosis and treatment in time, especially in children, pregnant women, and immunocompromised patients.
Conventional microscopic examination is a gold standard method and often used to identify the helminth ova and filariform larvae and also protozoa cyst in stool-dependent simple smear. Genus and species characterization of pathogenic parasites can be conducted based on their morphology and structure [2]. Nevertheless, shared common traits and background interference (tissue-debris and colors) during microscopic observation led to mistaken identification. The benefits of traditional techniques are diminished by time-consuming, complicated procedures, massive labor, and skilled and trained parasitologists.  An automatically rapid screening of the most in need of treatment is considered to replace the conventional technique.
Pattern recognition dependent pixel-wise classification to recognize any object with its structure, size, shape, and unique morphology is possibly used to overcome the conventional method described above. This pattern recognition technique is based on artificial intelligence (AI), machine learning (ML), and deep learning (DL) to compile with a whole slide scanner to help transfer the public-health services. ML is a scientific study of algorithms that deal with input under independent two-processes including feature extraction by engineer and learning transference by convolutional neural network (CNN). Previous study was proposed by [3] to characterize eggs of helminths, namely capillaria species deposited in institutional collections, by using logistic model tree algorithm combining with the majority voting algorithm resulting in high metric values [4]. DL, a current next generation of ML that both feature engineering and CNN learning are operated within a computerized system, was used to study 34 human parasite species based on various algorithm versions of You Only Look Once (YOLO). There are not only the proposed trained-model used to deal with the largest datasets, but state-of-the-art model also revealed performance with superior to localize and classify the helminths and protozoa with greater than 95% of both recall and precision, respectively [2]. 
The most effective and practical ML and DL applications tend to be supervised learning that requires a large sample size and high-quality trustworthy labels by skilled and trained doctors such as medical X-ray, CT scan, or MRI images. Self-supervised learning prone to a promising approach due to the technique can learn a bunch of datasets needing small proportions of labels ranging 1% to 10% of total data. Several self-supervised learning applications in a medical sector mainly used for histopathological images of cancer types [5]. These proposed the technique to estimate and diagnose interstitial pneumonia with a progressive course and poor prognosis due to poor reproducibility by pathologists reported [3]. The research result gave the prediction of pneumonia and a finding suggestive of progressive disease with high accuracy and AUC at 0.86. In addition, the classification of benign and malignant cells in lung cytological images with a weakly supervised deep learning method was also provided outstanding with 91.67% accuracy which comparable to senior and junior cytopathologist who have 98.34% and 83.34%, respectively [6]. As a result, the types of explainable AI can collaborate with human.
Here, we aim to develop a deep residual neural network based self-supervised learning model to identify mostly common parasite ova in Thailand. The aim of this study is to implement this Bootstrap Your Own Latent (BYOL) method and our model as invaluable tools for future parasitic infection screening, particularly in resource-limited settings.
Architecture
 
Fig. 1. Process Overview. The BYOL process (green box) generates a pre-trained weight file utilized in the fine-tuning of a new classification model (yellow box). The traditional supervised learning method is depicted in the blue box for comparative purposes.
The green box (see Fig. 1) is the part of self-supervised learning (SSL) based the BYOL method [7]. During the process, the data loader required the Nvidia-DALI to assist it as the data input step. Second part of the SSL, the pre-trained weight (an output) would be used to fine-tune the selected classification model by using new labels during training in the down steam section. In our study, we designed two-experiments to find the suitable model and also adjust the cost and effect amount of training data. Accompanying the protocols above, the first experiment was done by comparing their model performance between the combination of pre-trained weight connecting to fine tune the classification models and an individual classification model, the ResNet backbones.  In the second experiment, we want to find appropriate amount of training data in the downstream step to fine-tune the selected classification models, ResNet versions. Therefore, 1%, 10% and 20% of the labelled-training data were studied. Also, the compared result between that obtained from the second experiment and the single classification one could tell us the whether SSL is beyond the result of supervised learning (SL) model.
Materials and Method
Dataset collection 
All image data used in this studied were obtained from public dataset with url  [8]. Totally, 11-classes were recruited including Ascaris lumbricoides, Capillaria philippinensis, Enterobius vermicularis, Fasciolopsis buski, Hookworm egg, Hymenolepis diminuta, Hymenolepis nana, Opisthorchis viverrini, Paragonimus spp., Taenia spp., and Trichuris trichiura. Microscopic images, captured at 100x and 400x magnifications, presented varying image ratios. To focus on key objects, we increased each object's bounding box by a factor of 1.2 and cropped the images accordingly. These images were resized to a standard 608 x 608 pixel dimension and saved in PNG format with square padding. (see Fig. 2). In general, each class of parasites could be uniquely identified based on a combination of features such as the color of their egg-shell, the presence of certain organelles, and their size and shape [2].
 
Fig. 2. Genus and species of 11-helminth classes used in this study.

 
Fig. 3. Distribution of image datasets in Supervised Learning (SL), Self-Supervised Learning (SSL), and fine-tuning processes.
Fig. 3 provides an overview of the datasets used in the study. Dataset 1 (Training Dataset) consists of 8,800 labeled images and is used to train the Supervised Learning (SL) model. It is divided into four parts, representing 1%, 10%, 20%, and 100% of the original images. Dataset 2 (Pre-training Dataset) includes 8,800 unlabeled images and is used for pre-training the model using the Bootstrap Your Own Latent (BYOL) method. Dataset 3 (Fine-tuning Dataset) is identical in size to the Pre-training Dataset and is used for fine-tuning the model. It is also divided into four parts. Dataset 4 (Validation Dataset) contains 2,000 labeled images used for model validation during training. Dataset 5 (Testing Dataset) consists of 2,228 labeled images used to evaluate the final performance of the model.
3.2 Self-supervised learning and model training
BYOL algorithm of the self-supervised learning was used to accomplished our tasks, due to, its performance showed a greater than contrastive model (one of the state-of-the-art) [7]. We used three-ResNet versions to be our backbone, ResNet-50, ResNet-101 and ResNet-152 layers. As described as above, the well-pretrained weight file could be roughly assessed its performance by using the dimension reduction technique, namely Uniform Manifold Approximation and Projection (UMAP) to visualize the result of datapoint clustering. If the datapoints per class formed within a compact cluster, the pretrained weight would reach the excellent result at the downstream process finished (see Fig. 1).
Solo-learn. library equipped with various self-supervised learning algorithms, useful for machine learning tasks. Its synergy with Nvidia DALI, a tool for data management, allows it to efficiently handle data input, streamline preprocessing pipelines, and manage hyperparameters. Nvidia DALI also accelerates computations, contributing to quicker model training and inference. The combination of Solo-learn with Nvidia DALI provides an efficient environment for visualizing and implementing self-supervised learning methods, ensuring high-quality learning representations and optimal model performance [9].
Configuration.  Our training condition of the SSL were described in Table 2. In brief, we did vary the ResNet versions to find the suitable one for output representation.
Table 1. Hyperparameters and settings used in the Self-Supervised Learning (SSL) processes.
Parameter	Value
Backbone	ResNet-50, ResNet-101, ResNet-152
Data Format	Nvidia DALI
Label	No
Batch Size	64
Tau base	0.99
Tau final	1.00
Learning rate	0.125
Maximum epochs	6000
Optimizer	Lars
Loss in BYOL. Loss of BYOL method used is mean squared error by difference between L2 normalized online and target networks representations (see Fig. 1) [7].
L_(θ,ξ)≜ ∥ (q_θ ) ̅(z_θ )- z ̅'_ξ ∥_2^2 	(1)
Model can be used to initially observe the graph of training loss to see if whether it reached the saturation. Briefly, as seen in Fig. 3 the first 2000 epochs gave an increasing of the trending line. Then, swing line represented for non-saturated training found during the epochs of 2000 to 4000. We observed it reached a steady state during 5000 epochs to 6000 epochs of the training phase and inferring the optimum training (see Fig. 3).
 
Fig. 4. Training loss of backbone ResNet-50, ResNet-101 and ResNet-152
Dimension reduction. We used UMAP to achieve a hypothesis whether the pre-trained model has the capacity to differentiate to do clustering analysis of all datapoints per class. The UMAP of the ResNet-50 and ResNet-101 showed the most compact clustering of the datapoints more than ResNet-152(see Fig. 4). Therefore, both models may be evident of the similar performance in finding features and making a classification.
 
Fig. 5. UMAP of ResNet-50, ResNet-101, ResNet-152, respectively.
Downstream task and Supervised Learning (SL). The downstream task, set as a classification problem, was managed by a neural network fine-tuned with subsets of our labeled Dataset 1. This process initiated after the pre-training phase, in which we utilized the Bootstrap Your Own Latent (BYOL) method. Model architectures based on ResNet-50, ResNet-101, and ResNet-152 were employed, all fine-tuned with 11 helminthic labels. We used four subsets of Dataset 1 for this fine-tuning process: Dataset 3 (1% or 88 images), Dataset 4 (10% or 880 images), Dataset 5 (20% or 1,760 images), and Dataset 6 (100% or 8,800 images). Each subset was supplemented with 2,200 validation images and 2,228 testing images. In parallel, Supervised Learning (SL) was established as a benchmark process, where Dataset 1 was applied for training (8,800 images), validation (2,200 images), and testing (2,228 images). The comparison of the downstream task and SL allowed us to gauge the effectiveness of our fine-tuning approach versus traditional supervised learning, thereby helping us discern the optimal learning method and the ideal volume of training data required. The configurations used in our experiments are detailed in Table 3.
Table 2. Hyperparameters and settings used in the Supervised Learning (SL) and fine-tuning processes.
Parameter	Value
Backbone	ResNet-50, ResNet-101, ResNet-152
Data Format	Sub Folder
Label	Yes
Batch Size	32
Loss function	Cross-entropy
Learning rate	0.0001
Maximum epochs	500
Optimizer	Adam

 
Fig. 6. Training accuracy and training loss of trained ResNet-50, ResNet-101, ResNet-152 algorithms. Each trained model was shown by small amounts of training data used including 1% and 10% of self-supervised learning approaches which is compared to that of a supervised learning model.
3.3	Evaluation metric
The optimized trained model were then evaluated its quality performance to detect the intestinal helminthic objects from testing image set (see Fig. 5). The confusion matrix table was used to assess the statistical metric of precision, recall, specificity, F1 score and general accuracy [10]. All analyzed four interpretation values retrieved from the confusion matrix table as follow; true positive (TP), true negative (TN), false positive (FP), and false negative (FN), respectively. These values were used to calculated four statistical metrics as follow;
Precision=TP/(TP+FP) 	(2)
Recall=TP/(TP+FN)	(3)
Accuracy=(TP+TN)/(TP+TN+FP+FN)	(4)
Specificity=TN/(TN+FP) 	(5)
F1 score=(2 × Precision × Recall)/(Precision+Recall) 	(6)
Receiver Operating Characteristic (ROC) curve was plotted based Scikit-learn library under python software version. An area under the ROC curve (AUC) calculated based 95% confident interval was revealed the generalized accuracy of the proposed trained model.
Results
General accuracies by confusion matrix tables 
 
Fig. 7. Confusion matrix tables. The table show quality performance of trained SSL ResNet model versions and also represent them based on amounts of training data. Intensified color is positively correlated to degree of TP values. 
Accompanying the procedure in material method section, the classification model and the pre-trained weight were fine-tuned by 11-helminthic labels. The quality performance of the trained models was initially assessed by using the confusion matrix table as follows.
In the confusion matrix table, the intensified diagonal pattern (from left to right) represented high degree of the TP values of each trained models found (see Fig. 6). Although the trained SL approaches seem to have a better pattern of TP values than the SSL approaches, the trained SSL has less training data than the SL, emphasizing the remarkably cutting-edge technique. Observing the results visually, it is clear that the SSL-ResNet-101 and SSL-ResNet-152 models outperform the SSL-ResNet-50 model. Although SL models appear to be superior to SSL, the SSL can be compared to the SL since all trained-SSL with merely 10% training data produced low FN and FP values.
In SSL model, the performance of various training data based ResNet models is sporadic (see Table 4). For 1% training data, the ResNet-50 showed great value of 95.6% accuracy, 86.7% precision, and 99.1% specificity, the ResNet-101 for 66.6% recall and 74.4% F1 score, and the ResNet-152 for 96.2% accuracy. 
Table 3. Evaluation metrics including recall, precision, accuracy, specificity and F1 score, respectively.
Evaluation metrics	Models	SSL	SL
		1%	10%	20%	100%
Recall	ResNet-50	0.580	0.785	0.788	0.775
	ResNet-101	0.666	0.775	0.804	0.775
	ResNet-152	0.661	0.780	0.803	0.819
Precision	ResNet-50	0.867	0.923	0.898	0.875
	ResNet-101	0.855	0.925	0.913	0.875
	ResNet-152	0.852	0.906	0.908	0.910
Accuracy	ResNet-50	0.956	0.977	0.975	0.972
	ResNet-101	0.960	0.976	0.977	0.972
	ResNet-152	0.962	0.974	0.977	0.979
Specificity	ResNet-50	0.991	0.992	0.990	0.988
	ResNet-101	0.986	0.993	0.991	0.988
	ResNet-152	0.988	0.990	0.991	0.991
F1 score	ResNet-50	0.679	0.849	0.851	0.835
	ResNet-101	0.744	0.842	0.863	0.835
	ResNet-152	0.740	0.843	0.863	0.877

For 10% training data, only ResNet-50 and ResNet-101 models gave highest value at 78.5% recall, 92.5% precision, 97.7% accuracy, 99.3% specificity and 87.9% F1 score.
For 20% training data, most statistical metrics at 97.7% accuracy, 99.1% specificity and 86.3% F1 score were measured from both the ResNet-101 and ResNet-152 models, respectively. Only two statistical metrics of 80.4% and 91.3% precision was obtained from the ResNet-101 model. In summary, significant correlation between the small amounts of training data ranging 1% to 10% and ResNet-50 and ResNet-101 models was observed. During limitation of biological variation and quality of its labels, these uncontrolled factors might be solved by using only 1% of the training data and then results in 86.7% precision, 96.2% accuracy and 99.1% specificity, respectively. The result indicated that the SSL technique is moving forward to undergo the opened-world datasets which are mostly unlabeled as effective. 
Performances of various models
In consistent to those described as above, the AUC supported the performances of 10% of training data-based SSL-ResNet-50 (AUC = 0.944) and SSL-ResNet-101 (AUC = 0.946) model revealed outperform when comparing to others (see Fig. 7). Interestingly, only 1% of training data reproduced the AUC equal to 89.9%, which suggesting high enough to employ the trained model in a real situation. The idea was supported by the result seen in Fig. 8. Also, the positive correlation between 10% of training data-based SSL-ResNet-101 model was shown (see Fig. 8). Although the utilization of small neural network layers by the ResNet-50 model was trained with 1% data, the AUC still showed similar result to SL model. This indicated that the SSL technique is superior to the SL model.
 
Fig. 8. ROCs for assessing general accuracy of supervised comparing to self-supervised models.
 
Fig. 9. Comparison of AUC among SSL against SL models. We highlighted small amounts of labelled training data ranking 1% to 10%.
Discussion and conclusion
In this study, 11-common human-helminthic eggs in Thailand were automatic screening by using self-supervised learning approach. As workflow and architecture, our proposed algorithm contained two main components, namely online network that function to prepare feature extraction without class labelling and do data clustering-based similarity loss function. In our experiment, then, the result from previous section were used to do classification under labelling with multiclass-classification processes. Remarkably, the model trained with the advanced BYLO method outperformed the supervised learning model using ResNet. This was achieved even when a small fraction of the dataset, ranging from 1% to 10%, was employed for training and validation, highlighting the efficiency of the BYLO method in leveraging limited data resources. As mentioned as above, SSL approach for classifying our unseen image dataset is comparable to previous works based only on object detection [10-12], suggesting the superior model to supervised ones. This is because our SSL approach used trained data less than and equal to 10% of training data and reveal ranging of 87% to 99% accuracy, precision and specificity, respectively. According to the result mentioned as above, it can be assured that SSL is beneficial to solve the biological and medical tasks with still affecting by some serious issues such as high variation and a large amount of deposited data such as chest X-rays, CT-scans, MRI images, and whole slide images which these had been intensively investigated based on supervised learning network. In addition, the corrected prediction result of supervised learning model is depending on sample size with needs qualitative labels by expert clinicians [13, 14]. If the trained model was consumed garbage labels, the results would give the garbage output found.
Nevertheless, the training SSL model might experience with some limitations such as well-trained model could require the numbers of feature extracted and the more number feature vector such as either 1024 or 2048 vectors, the higher performance received than less one such as 64 vectors. Furthermore, even though the SSL approach uses a smaller sample size with less data labeling during training and validation, the optimized model required a potential region with high variation[15]. Nevertheless, this step could be fixed by implementing the augmentation function before doing training data. Lastly, computational speed still requires, specifically training with a large validation.
In conclusion, we proposed the outstanding the classification algorithm-based SSL approach to solve the biological and medical tasks including a large unstructured/ structured data. In Thailand, incidence of human helminth infection is currently reported along rural area from several sources such as Thai’s CDC, ministry of health and also academic publications. Although, current anti-helminth drugs are available with convenient accessible at any drug store, ignorant behavior for stool examination during annual check-up and traditional meal with raw cook remains an existing transmission of the parasite in Southeast Asian countries. Automatic screening device (for example; smartphone application) based deployed SSL approach is new hope to support the clinical-decision making in remote area where is lack of expert technicians. 
Competing interests
The authors declare no competing interest.
Data availability 
The data that support the findings of this study are upon requested to the corresponding author.
Acknowledgement
We are grateful to the National Research Council of Thailand (NRCT) [NRCT5-RSA63001-10] for providing the financial support for this research project. 
Author’s contribution.
N.P., and S.C. conceived and designed the research study; N.P., and V.K. wrote the manuscript; N.P. performed the computational experiment; N.P., V.K., S.C., and S.B. performed data analysis; N.P., R.J., K.J., and S.C. collected data; T.T., S.C. and S.B. conducted the computer’s platform. S.B., and S.C. read and approved the final manuscript.

References Uncategorized References
1.	Kache, R., Phasuk, N., Viriyavejakul, P., Punsawad, C.: Prevalence of soil-transmitted helminth infections and associated risk factors among elderly individuals living in rural areas of southern Thailand. BMC Public Health 20, 1882 (2020)
2.	Naing, K.M., Boonsang, S., Chuwongin, S., Kittichai, V., Tongloy, T., Prommongkol, S., Dekumyoy, P., Watthanakulpanich, D.: Automatic recognition of parasitic products in stool examination using object detection approach. PeerJ Computer Science 8, e1065 (2022)
3.	Uegami, W., Bychkov, A., Ozasa, M., Uehara, K., Kataoka, K., Johkoh, T., Kondoh, Y., Sakanashi, H., Fukuoka, J.: MIXTURE of human expertise and deep learning-developing an explainable model for predicting pathological diagnosis and survival in patients with interstitial lung disease. Mod Pathol 35, 1083-1091 (2022)
4.	Zhong, A., Li, X., Wu, D., Ren, H., Kim, K., Kim, Y., Buch, V., Neumark, N., Bizzo, B., Tak, W.Y., Park, S.Y., Lee, Y.R., Kang, M.K., Park, J.G., Kim, B.S., Chung, W.J., Guo, N., Dayan, I., Kalra, M.K., Li, Q.: Deep metric learning-based image retrieval system for chest radiograph and its clinical applications in COVID-19. Med Image Anal 70, 101993 (2021)
5.	Chen, R.J., Lu, M.Y., Williamson, D.F.K., Chen, T.Y., Lipkova, J., Noor, Z., Shaban, M., Shady, M., Williams, M., Joo, B., Mahmood, F.: Pan-cancer integrative histology-genomic analysis via multimodal deep learning. Cancer Cell 40, 865-878.e866 (2022)
6.	Xie, X., Fu, C.-C., Lv, L., Ye, Q., Yu, Y., Fang, Q., Zhang, L., Hou, L., Wu, C.: Deep convolutional neural network-based classification of cancer cells on cytological pleural effusion images. Modern Pathology 35, 609-614 (2022)
7.	Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M.: Bootstrap your own latent-a new approach to self-supervised learning. Advances in neural information processing systems 33, 21271-21284 (2020)
8.	Suwannaphong, T., Chavana, S., Tongsom, S., Palasuwan, D., Chalidabhongse, T.H., Anantrasirichai, N.: Parasitic egg detection and classification in low-cost microscopic images using transfer learning. arXiv preprint arXiv:2107.00968 (2021)
9.	Da Costa, V.G.T., Fini, E., Nabi, M., Sebe, N., Ricci, E.: solo-learn: A Library of Self-supervised Methods for Visual Representation Learning. J. Mach. Learn. Res. 23, 1-6 (2022)
10.	Kittichai, V., Kaewthamasorn, M., Thanee, S., Jomtarak, R., Klanboot, K., Naing, K.M., Tongloy, T., Chuwongin, S., Boonsang, S.: Classification for avian malaria parasite Plasmodium gallinaceum blood stages by using deep convolutional neural networks. Scientific Reports 11, 16919 (2021)
11.	Butploy, N., Kanarkard, W., Maleewong Intapan, P.: Deep Learning Approach for Ascaris lumbricoides Parasite Egg Classification. Journal of Parasitology Research 2021, 6648038 (2021)
12.	Holmström, O., Linder, N., Ngasala, B., Mårtensson, A., Linder, E., Lundin, M., Moilanen, H., Suutala, A., Diwan, V., Lundin, J.: Point-of-care mobile digital microscopy and deep learning for the detection of soil-transmitted helminths and Schistosoma haematobium. Glob Health Action 10, 1337325 (2017)
13.	Jiang, H., Zhou, Y., Lin, Y., Chan, R.C.K., Liu, J., Chen, H.: Deep learning for computational cytology: A survey. Medical Image Analysis 84, 102691 (2023)
14.	Jahn, S.W., Plass, M., Moinfar, F.: Digital Pathology: Advantages, Limitations and Emerging Perspectives. J Clin Med 9, (2020)
15.	Li, S., Du, Z., Meng, X., Zhang, Y.: Multi-stage malaria parasite recognition by deep learning. Gigascience 10, (2021)


![image](https://github.com/tss2tss/moti/assets/112949175/666d84bd-d4fd-4252-b031-25e7cd844d69)
